{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Pandas\" data-toc-modified-id=\"Pandas-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Pandas</a></span><ul class=\"toc-item\"><li><span><a href=\"#Чтение-файла\" data-toc-modified-id=\"Чтение-файла-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Чтение файла</a></span><ul class=\"toc-item\"><li><span><a href=\"#CSV\" data-toc-modified-id=\"CSV-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>CSV</a></span></li><li><span><a href=\"#Читаем-файл\" data-toc-modified-id=\"Читаем-файл-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Читаем файл</a></span></li><li><span><a href=\"#Беглый-взгляд-на-данные\" data-toc-modified-id=\"Беглый-взгляд-на-данные-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Беглый взгляд на данные</a></span></li></ul></li><li><span><a href=\"#Простые-фильтрации\" data-toc-modified-id=\"Простые-фильтрации-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Простые фильтрации</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логическое-&quot;И&quot;\" data-toc-modified-id=\"Логическое-&quot;И&quot;-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Логическое \"И\"</a></span></li><li><span><a href=\"#Логическое-&quot;ИЛИ&quot;\" data-toc-modified-id=\"Логическое-&quot;ИЛИ&quot;-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Логическое \"ИЛИ\"</a></span></li><li><span><a href=\"#Логическое-&quot;НЕ&quot;\" data-toc-modified-id=\"Логическое-&quot;НЕ&quot;-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Логическое \"НЕ\"</a></span></li></ul></li><li><span><a href=\"#Функции-фильтры\" data-toc-modified-id=\"Функции-фильтры-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Функции-фильтры</a></span><ul class=\"toc-item\"><li><span><a href=\"#.isna()\" data-toc-modified-id=\".isna()-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span><code>.isna()</code></a></span></li><li><span><a href=\"#.isin()\" data-toc-modified-id=\".isin()-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span><code>.isin()</code></a></span></li></ul></li><li><span><a href=\"#Series-и-Index\" data-toc-modified-id=\"Series-и-Index-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Series и Index</a></span></li><li><span><a href=\"#Индекс\" data-toc-modified-id=\"Индекс-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Индекс</a></span><ul class=\"toc-item\"><li><span><a href=\"#Изменение-значения-через-.loc\" data-toc-modified-id=\"Изменение-значения-через-.loc-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Изменение значения через <code>.loc</code></a></span></li></ul></li><li><span><a href=\"#Группировка\" data-toc-modified-id=\"Группировка-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Группировка</a></span></li><li><span><a href=\"#Время-и-даты\" data-toc-modified-id=\"Время-и-даты-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Время и даты</a></span></li><li><span><a href=\"#Простая-визуализация\" data-toc-modified-id=\"Простая-визуализация-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Простая визуализация</a></span><ul class=\"toc-item\"><li><span><a href=\"#Линии-и-точки-по-данным\" data-toc-modified-id=\"Линии-и-точки-по-данным-1.8.1\"><span class=\"toc-item-num\">1.8.1&nbsp;&nbsp;</span>Линии и точки по данным</a></span></li><li><span><a href=\"#Гистограммы\" data-toc-modified-id=\"Гистограммы-1.8.2\"><span class=\"toc-item-num\">1.8.2&nbsp;&nbsp;</span>Гистограммы</a></span></li><li><span><a href=\"#Точная-настройка-через-matplotlib\" data-toc-modified-id=\"Точная-настройка-через-matplotlib-1.8.3\"><span class=\"toc-item-num\">1.8.3&nbsp;&nbsp;</span>Точная настройка через matplotlib</a></span></li></ul></li><li><span><a href=\"#Сохранение-данных\" data-toc-modified-id=\"Сохранение-данных-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Сохранение данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#CSV\" data-toc-modified-id=\"CSV-1.9.1\"><span class=\"toc-item-num\">1.9.1&nbsp;&nbsp;</span>CSV</a></span></li><li><span><a href=\"#Excel\" data-toc-modified-id=\"Excel-1.9.2\"><span class=\"toc-item-num\">1.9.2&nbsp;&nbsp;</span>Excel</a></span></li></ul></li></ul></li></ul></div>"
   ],
   "id": "2e4aef1b476e11c8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "Этот урок мы посвятим целиком знакомству с библиотекой `pandas`. \n",
    "\n",
    "Мы научимся читать файлы, фильтровать и аггрегировать данные, получать инсайты о данных и записывать свои находки в файлы. Это самые часто встречающиеся операции в `pandas` на практике."
   ],
   "id": "534cf45617354ca1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение файла\n",
    "Обычно работа с данными начинается с их чтения :)\n",
    "\n",
    "Pandas умеет читать данные в самых разных формах хранения:\n",
    "1. CSV (comma separated values, простой формат хранения таблиц).\n",
    "2. Excel таблицы.\n",
    "3. Напрямую из баз данных.\n",
    "4. Веб-форматы: `json`, `xml`.\n",
    "5. Специальные форматы для данных: `parquet`, `feather`, `orc`.\n",
    "\n",
    "Мы сегодня научимся читать CSV. Это очень простой формат, и из-за этого такой популярный: почти во всех соревнованиях по data science входные данные дают именно в CSV.\n",
    "\n",
    "Не переживайте, pandas всегда будет приводить все читаемые данные к одному формату - поэтому вы без труда сможете открыть любой другой источник, если будете уметь работать с CSV.\n",
    "\n",
    "### CSV\n",
    "\n",
    "Формат CSV очень простой: на каждую запись выделяется отдельная строка, а колонки отделяются специальным символом (по умолчанию запятой `,`).\n",
    "\n",
    "Так, таблица \n",
    "\n",
    "| Имя  | Возраст | Город    |\n",
    "|------|---------|----------|\n",
    "| Миша | 28      | Москва   |\n",
    "| Саша | 12      | Казань   |\n",
    "| Илья | 54      | Мурманск |\n",
    "\n",
    "будет выглядеть как\n",
    "```csv\n",
    "Имя,Возраст,Город\n",
    "Миша,28,Москва\n",
    "Саша,12,Казань\n",
    "Илья,54,Мурманск\n",
    "```\n",
    "\n",
    "### Читаем файл\n",
    "Мы заранее подготовили файлик CSV с данными.\n",
    "Эти данные взяты из [соревнования на Kaggle](https://www.kaggle.com/c/bike-sharing-demand/data?select=train.csv). Kaggle - это площадка для соревнований в области Data Science, где любой может посоревноваться и выиграть денежную награду.\n",
    "\n",
    "Данные представляют из себя записи об аренде велосипедов в разные дни:\n",
    "1. Дата и время (промежуток 1 час)\n",
    "2. Какое время года\n",
    "3. Погода\n",
    "4. Сколько было аренд среди зарегистрированных пользователей\n",
    "5. Сколько было аренд среди незарегистрированных пользователей"
   ],
   "id": "a5fbc2577eb1a36d"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:18:24.180155Z",
     "start_time": "2024-04-02T09:18:22.905740Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# CSV файл читается функцией read_csv\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\StartML-c-K7MfSX\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m   1014\u001B[0m     dialect,\n\u001B[0;32m   1015\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m   1023\u001B[0m )\n\u001B[0;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\StartML-c-K7MfSX\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\.virtualenvs\\StartML-c-K7MfSX\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\StartML-c-K7MfSX\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1887\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1889\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\.virtualenvs\\StartML-c-K7MfSX\\lib\\site-packages\\pandas\\io\\common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# CSV файл читается функцией read_csv\n",
    "df = pd.read_csv('train.csv')"
   ],
   "id": "740f178d4105ad7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:18:24.184316Z",
     "start_time": "2024-04-02T09:18:24.183295Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ],
   "id": "bb21c0cdd4a1c0f1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы только что считали CSV и сохранили как `DataFrame` - тип данных из библиотеки pandas.\n",
    "\n",
    "Давайте посмотрим на то, какие возможности дает `DataFrame`.\n",
    "\n",
    "### Беглый взгляд на данные\n",
    "В `pandas` можно быстро взглянуть на основные характеристики данных:"
   ],
   "id": "7a11c398ce57758d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Показать первые 5 записей\n",
    "# Можно передать аргумент - столько и покажет\n",
    "# Полезно, чтобы взглянуть на данные\n",
    "df.head()"
   ],
   "id": "76e38182a9e87621"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.186317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Подсчитать количество заполненных записей (count),\n",
    "# среднее (mean),\n",
    "# стандартное отклонение (std),\n",
    "# квантили (25%, 50%, 75%),\n",
    "# минимум и максимум (min и max соответственно)\n",
    "# для каждой колонки с числами\n",
    "# Полезно, чтобы посмотреть на масштаб величин и их разброс\n",
    "df.describe()"
   ],
   "id": "a1377ff2554a09e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.187315Z"
    }
   },
   "outputs": [],
   "source": [
    "# Посмотреть на колонки\n",
    "df.columns"
   ],
   "id": "f5578b4bcd399984"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.188315Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns[1:5]"
   ],
   "id": "372616b718d99641"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# И их типы (строки и плохо прочитанные даты помечаются как object)\n",
    "df.dtypes  # d - дата, то есть data types"
   ],
   "id": "55c37d083cece46a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Простые фильтрации\n",
    "В pandas можно быстро и просто фильтровать данные по значениям.\n",
    "Фильров может быть сколько угодно, и они могут быть весьма комплексными."
   ],
   "id": "a3409f9a44537b16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.189318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Можно фильтровать данные через квадратные скобки\n",
    "df[df['workingday'] == 0]  # получить все поездки за выходные\n",
    "\n",
    "# Этот запрос можно читать как \"взять df, где у df поле workingday равно 0\""
   ],
   "id": "f63ff20ddf5d0138"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логическое \"И\"\n",
    "Можно потребовать, чтобы выполнилось несколько условий одновременно.\n",
    "Для этого используется оператор `&`:"
   ],
   "id": "ee4850bec7d2be05"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.190317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Можно задавать несколько условий\n",
    "# Переносы строк внутри [] не играют роли - мы их делаем только для читаемости\n",
    "df[\n",
    "    (df['workingday'] == 1) & (df['season'] == 1)\n",
    "]\n",
    "\n",
    "# Получим весенние поездки в рабочие дни"
   ],
   "id": "776ae56048722b4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу отметим две вещи:\n",
    "1. `&` в pandas означает логическое \"И\" - требование, чтобы оба условия выполнились. Обратите внимание, в питоне есть `and` для логического \"И\" в булевых выраженях. Например, можно написать:\n",
    "```python\n",
    "if var1 is None and len(arr) > 0:\n",
    "     print('var1 is None and array \"arr\" has length > 0')\n",
    "```\n",
    "но в pandas используется **только** `&`. Это из-за того, что выражения `df['workingday'] == 1` не являются булевыми типами (об этом немного позже).\n",
    "2. Оба условия обернуты в скобки. В pandas так стоит делать всегда, так как без них оператор `&` будет выполняться в неправильном порядке и код не запустится.\n",
    "\n",
    "### Логическое \"ИЛИ\"\n",
    "Логическое \"ИЛИ\" делается через символ `|`.\n",
    "Оно требует выполнения хотя бы одного условия из всех.\n",
    "Заметьте, нельзя использовать питоновский `or`, как и в случае с логическим \"И\" (оператор `&`)."
   ],
   "id": "d5ffe8cf5d8c7207"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.191316Z"
    }
   },
   "outputs": [],
   "source": [
    "# Либо влажность < 10%, либо температура в Цельсиях строго больше 30\n",
    "df[\n",
    "    (df['humidity'] < 10) | (df['temp'] > 30.)\n",
    "]"
   ],
   "id": "3cd6800b788cc52"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логическое \"НЕ\"\n",
    "Логическое \"НЕ\" делается через символ `~`. Точно так же, как в прошлых операторах, встроенный в Python `not` не подойдет."
   ],
   "id": "823023ed04974c74"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.192315Z"
    }
   },
   "outputs": [],
   "source": [
    "# Не забудьте про скобки, иначе ~ применится в неправильном порядке и получим некорректный результат\n",
    "df[\n",
    "    ~(df['workingday'] == 0)\n",
    "]"
   ],
   "id": "3c4ec4187383e97f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Когда объединяете \"НЕ\" с другими условиями, окружите его тоже скобками\n",
    "df[\n",
    "    (~(df['workingday'] == 0)) & (df['temp'] >= 10) & (df['temp'] < 30)\n",
    "]\n",
    "# Не рабочий день и температура от 10 включительно до 30 не включительно\n",
    "# можно было использовать df['workingday'] != 0"
   ],
   "id": "5d83138bd96ecd60"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции-фильтры\n",
    "В pandas есть много функций для сложных проверок.\n",
    "Пройдемся по главным.\n",
    "### `.isna()`\n",
    "Фильтрует по записям, в которых пропущено значение.\n",
    "Обратите внимание, **нельзя** использовать конструкцию\n",
    "```python\n",
    "df[df['windspeed'] is None]\n",
    "```"
   ],
   "id": "2de725941743a66"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.193316Z"
    }
   },
   "outputs": [],
   "source": [
    "# взять df, где у df поле windspeed не заполнено\n",
    "df[df['windspeed'].isna()]"
   ],
   "id": "3aef410e22ffe252"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ничего нет. Это хороший знак - у нас нет пропусков в поле `windspeed`."
   ],
   "id": "74f644e16822829a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.194316Z"
    }
   },
   "outputs": [],
   "source": [
    "# Можно применить функцию над целым DataFrame\n",
    "# True положится в места, где пропущено значение\n",
    "df.isna()"
   ],
   "id": "65ad8516020531bf"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T17:01:14.777738Z",
     "start_time": "2021-12-05T17:01:14.773584Z"
    }
   },
   "source": [
    "Судя по всему, у нас вообще все замечательно и пропусков нет нигде.\n",
    "Давайте проверим."
   ],
   "id": "1ca36a2018dbc91e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.195316Z"
    }
   },
   "outputs": [],
   "source": [
    "df['workingday'].isna().any()"
   ],
   "id": "72fbb00b5372563c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.196320Z"
    }
   },
   "outputs": [],
   "source": [
    "if df.isna().any().any():  # Первый any сворачивает до уровня колонок, второй сворачивает в одно значение\n",
    "    print('если пропуски')\n",
    "else:\n",
    "    print('пропусков нет')"
   ],
   "id": "289afff178e77aea"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.isin()`\n",
    "Проверяет, находится ли значение в разрешенном списке.\n",
    "\n",
    "Как и в `.isna()`, мы не можем использовать питоновскую конструкцию `in`:\n",
    "```python\n",
    "df[df['season'] in (1, 2)]\n",
    "```\n",
    "\n",
    "Вместо этого приходится пользоваться `.isin()`. Он работает точно так же."
   ],
   "id": "e0bde10c341c72b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.197318Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df['season'].isin([1, 3, 4])]"
   ],
   "id": "dbff20425dfd6320"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В pandas есть дополнительные функции для работы со строками и датами.\n",
    "Их подробнее рассмотрим в домашней работе."
   ],
   "id": "fddbf34a74320898"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series и Index\n",
    "Примеры выше могли оставить несколько вопросов.\n",
    "1. Почему не работают встроенные `in`, `not`?\n",
    "2. Откуда такой странный синтаксис с квадратными скобками?\n",
    "3. Что будет, если вызвать просто `df['season'] == 1`? Это `True/False` или что-то другое?\n",
    "\n",
    "Давайте начнем с 3-его вопроса:"
   ],
   "id": "5ba20be74666cb5c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.198318Z"
    }
   },
   "outputs": [],
   "source": [
    "df['season'] == 1"
   ],
   "id": "7aa875d2b8a4e8a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это не `True/False`, а массив из `True/False`!\n",
    "Слева видим числа - это _индекс_ (англ. _index_). Про него расскажем чуть позже.\n",
    "\n",
    "Во всех примерах фильтры на самом деле возвращали объект _Series_.\n",
    "На _Series_ можно смотреть как на DataFrame с одной колонкой.\n",
    "Когда мы вызывали\n",
    "```python\n",
    "df[df['season'] == 1]\n",
    "```\n",
    "мы сначала создавали _Series_ в куске `df['season'] == 1`, затем отдавали в `df[...]`.\n",
    "\"Под капотом\" происходило следующее: pandas искал в Series значения `True`, запоминал их индекс, а затем в оригинальном датафрейме `df` забирал значения по этому индексу.\n",
    "\n",
    "Такое использование _Series_ для логических проверок привело к тому, что встроенные в питон `in` и `not` не работают.\n",
    "Просто запомните, что вместо `df[\"col1\"] in [1, 2, 3]` надо использовать `df[\"col1\"].isin([1, 2, 3])`, а вместо `not` использовать символ `~`."
   ],
   "id": "65d3515092583ea4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Индекс\n",
    "Индекс в pandas похож на индекс в списках и на ключ в словаре. По элементу индекса можно отбирать элементы:"
   ],
   "id": "612fa11b593a6a4d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.199317Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "id": "8f682c766c1fe869"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.200318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Для \"прямого\" обращения по индексу используется .loc\n",
    "df.loc[4]  # вернет объект Series с колонками"
   ],
   "id": "a821a52b8db178ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.201318Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[4]['temp']"
   ],
   "id": "4a3d2ac23acf27b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.201318Z"
    }
   },
   "outputs": [],
   "source": [
    "# В качестве индекса может быть что угодно\n",
    "# Можно поставить любую колонку в качестве индекса\n",
    "df_dt = df.copy().set_index('datetime')\n",
    "df_dt.head(3)"
   ],
   "id": "eea632c39a35016a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.202319Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dt.loc['2011-01-01 01:00:00']  # забираем теперь по-другому"
   ],
   "id": "cc42dbb5675dcf97"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.204321Z"
    }
   },
   "outputs": [],
   "source": [
    "# есть способ забрать по порядку, а не по индексу - .iloc\n",
    "df_dt.iloc[4]"
   ],
   "id": "2c9a5c036584ba05"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# а еще есть вариант указать сразу и индекс, и колонку - через запятую\n",
    "df_dt.loc['2011-01-01 01:00:00', 'weather']\n",
    "# для .iloc такое не работает, приходится писать через две скобки\n",
    "# df_dt.iloc[4]['weather']"
   ],
   "id": "7194e8ba7921508f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.207317Z"
    }
   },
   "outputs": [],
   "source": [
    "# для .loc работает все, что мы знаем из срезов\n",
    "# при указании диапазона берутся все данные, которые лежат между ними\n",
    "# в текущей сортировке\n",
    "df_dt.loc['2011-01-01 01:00:00':'2011-01-01 03:00:00']"
   ],
   "id": "14ec265a56a6c556"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.208320Z"
    }
   },
   "outputs": [],
   "source": [
    "# для iloc работает все, что мы знаем из срезов\n",
    "df_dt.iloc[10:20:2]"
   ],
   "id": "ae5a20ed52b24c37"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изменение значения через `.loc`\n",
    "`df.loc[...]` позволяет перезаписывать значения - точно по такой же логике, как перезапись значения в словаре по ключу."
   ],
   "id": "4d45ffa979841876"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.209318Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dt.loc['2011-01-01 04:00:00', 'weather'] = 234  # элемент с индексом 4\n",
    "df_dt.iloc[4]['weather']  # проверим перезапись"
   ],
   "id": "7c6baf3cf747a94"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.210317Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dt.iloc[4]['weather'] = -5 # не сработает"
   ],
   "id": "37bc0d275b69d726"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.211317Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dt.iloc[4]['weather']"
   ],
   "id": "ea68b1d615b7b325"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# индекс можно сбросить на 0, 1, 2\n",
    "df_dt.reset_index()  # возвращает копию, НЕ редактирует исходный датафрейм"
   ],
   "id": "67c72acca292b6b9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Группировка"
   ],
   "id": "ea9d692cbb9268f8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хорошо, умеем фильтровать данные.\n",
    "Тем не менее, часто поступают запросы на подсчет какой-то агрегированной величины среди определенной группы данных.\n",
    "\n",
    "Скажем, может поступать запрос \"подсчитай суммарную выручку в разбивке по кварталам\" или \"подсчитай среднее число пользователей за день для каждого дня с начала года\".\n",
    "Особенность таких запросов в том, что их обработка строится в несколько действий:\n",
    "\n",
    "1. Отбираем подмножество по определенному критерию.\n",
    "2. Над подмножеством применяем функцию, которая вернет одно число (т.е. превратит **целое подмножество** в **одно** число).\n",
    "3. Возвращаемся в п.1, отбираем другое подмножество, повторяем алгоритм.\n",
    "4. Возвращаем все полученные агрегации.\n",
    "\n",
    "Такие задачи решаются через **группировку** данных с последующей **агрегацией**.\n",
    "В `pandas` есть все инструменты для решения."
   ],
   "id": "9630927568fcece5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.214318Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "попросили посчитатать среднюю температуру в разбивке по сезонам.\n",
    "Для этого надо сгруппировать по сезонам, т.е.\n",
    "сделать 4 подмножества данных - по одному на каждый сезон,\n",
    "затем каждую группу \"схлопнуть\" до одного числа - среднего по подмножеству.\n",
    "Получим 4 числа - по одному среднему на каждую группу.\n",
    "\"\"\"\n",
    "# Такой способ рекомендуется использовать\n",
    "df.groupby('season').agg({'temp': 'mean'})\n",
    "# сначала группируем по значению season,\n",
    "# затем просим из каждой группы взять колонку temp и подсчитать mean - среднее\n",
    "# mean - это специальная строка, принимает только определенные значения\n",
    "\n",
    "# доступные функции можно найти здесь\n",
    "# https://stackoverflow.com/questions/53943319/what-are-all-python-pandas-agg-functions?rq=1"
   ],
   "id": "e52ebe68387dbedb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.215324Z"
    }
   },
   "outputs": [],
   "source": [
    "# группировать можно сразу по нескольким параметрам\n",
    "# так мы подсчитаем среднее для всех колонок\n",
    "df.groupby(['season', 'workingday']).mean()"
   ],
   "id": "ebf04c10891691c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.216318Z"
    }
   },
   "outputs": [],
   "source": [
    "# а так - только для humidity\n",
    "df.groupby(['season', 'workingday'])['humidity'].mean()\n",
    "# равнозначный код\n",
    "# df.groupby(['season', 'workingday']).agg({'humidity': 'mean'})"
   ],
   "id": "8cc512f44d8f71e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.217320Z"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby(['season', 'workingday'])"
   ],
   "id": "6a546fab3e2c942a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Время и даты"
   ],
   "id": "4f7b4e08f8861dbe"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время и дата в pandas имеют свои особенности, поэтому про них поговорим отдельно.\n",
    "\n",
    "Мы уже знаем `datetime.datetime` и `datetime.date` и использовали их на практике.\n",
    "Но `pandas` имеет свои типы для работы со временем!\n",
    "Это сделано так потому, что библиотека `datetime` не дает той гибкости в работе, которую хотел реализовать pandas.\n",
    "Придется разбираться с этим новым типом. Знакомьтесь, `pd.datetime`."
   ],
   "id": "9f81a2ef90342953"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.218320Z"
    }
   },
   "outputs": [],
   "source": [
    "# К счастью, любой тип (не только datetime.datetime, но и строки, и числа)\n",
    "# можно преобразовать к pd.datetime\n",
    "pd.to_datetime(df['datetime']) # после преобразования"
   ],
   "id": "573ffb2aa5ac5b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.220316Z"
    }
   },
   "outputs": [],
   "source": [
    "# до преобразования\n",
    "df['datetime']"
   ],
   "id": "510fd467626f6c2f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На первый вгляд кажется, что ничего не поменялось. Но посмотрите на тип - без преобразования он был `object`, а с преобразованием стал `datetime64[ns]`. Второй тип более точно умеет работать со временем.\n",
    "\n",
    "Давайте посмотрим, чего же такого хорошего нам дал `pd.datetime`"
   ],
   "id": "802011e1465a0afe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.221320Z"
    }
   },
   "outputs": [],
   "source": [
    "# сохраним результат: создадим копию и в ней превратим колонку в pd.datetime\n",
    "df_1 = df.copy()\n",
    "df_1['datetime'] = pd.to_datetime(df_1['datetime'])\n",
    "df_1.head()"
   ],
   "id": "17a37c86a0c558e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.222320Z"
    }
   },
   "outputs": [],
   "source": [
    "# Теперь можно вытягивать куски из даты и использовать в фильтрациях и аггрегациях\n",
    "# Используйте .dt, чтобы вытащить не саму дату, а какую-то ее часть\n",
    "df_1[df_1['datetime'].dt.month == 5]  # через .dt взяли месяц\n",
    "# получили данные за пятый месяц"
   ],
   "id": "1a810ccea8227db9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В исходном `df` колонка `datetime` считается просто строкой, и `pandas` никак не понимает, что там лежит дата!"
   ],
   "id": "1fc7b6020d5b0eee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.223320Z"
    }
   },
   "outputs": [],
   "source": [
    "# выдаст ошибку, т.к. пандас не считал это как дату\n",
    "try:\n",
    "    df[df['datetime'].dt.month == 5]\n",
    "except:\n",
    "    print(\"Не работает\")"
   ],
   "id": "8ae1b4427940d05"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как можно сделать группировки с использованием `pd.datetime`."
   ],
   "id": "17b4b6006e133a24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.224318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Можно использовать .dt.month, чтобы сгруппировать по месяцам\n",
    "df_1.groupby(\n",
    "    df_1['datetime'].dt.month  # для каждого месяца\n",
    ").agg({\n",
    "    'temp': 'mean',  # узнаем среднюю температуру\n",
    "    \"humidity\": 'min'  # и минимальную влажность\n",
    "})  # в разбивке по месяцам"
   ],
   "id": "8232cd97d34b532d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.225319Z"
    }
   },
   "outputs": [],
   "source": [
    "# для даты можно узнать день, месяц, день недели, номер недели, год\n",
    "# документация https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#time-date-components\n",
    "rents_by_week = df_1.groupby(\n",
    "    df_1['datetime'].dt.weekofyear\n",
    ").agg({\n",
    "    'temp': 'count'\n",
    "})\n",
    "# sample(10) - это взять 10 случайных записей\n",
    "# Чтобы была воспроизводимость, фиксируем random_state\n",
    "rents_by_week.sample(10, random_state=42)\n",
    "# количество поездок в разбивке по неделям"
   ],
   "id": "94622af09195201"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Простая визуализация"
   ],
   "id": "5f142d4b4bf4c2f9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В примере выше мы получили разбивку числа поездок по неделям.\n",
    "Получилась большая таблица, и она весьма трудна для чтения.\n",
    "Давайте ее визуализируем."
   ],
   "id": "d1b02a2558a1f9aa"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линии и точки по данным"
   ],
   "id": "173440fc924f8030"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.227319Z"
    }
   },
   "outputs": [],
   "source": [
    "# самые простой способ - попросить pandas нарисовать\n",
    "# но контроля над картинками будет мало\n",
    "rents_by_week.plot(\n",
    "    # названия агрументов приходят из matplotlib.pyplot, см. ниже\n",
    "    xlabel='Номер недели',\n",
    "    ylabel='Число поездок',\n",
    "    title='Количество поездок понедельно',\n",
    "    grid=True,\n",
    "    figsize=(16, 9)\n",
    ")"
   ],
   "id": "e1981d213cb83b6f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гистограммы"
   ],
   "id": "a36613092c74e3ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.228319Z"
    }
   },
   "outputs": [],
   "source": [
    "# Также в pandas есть встроенная функция для постройки гистограм\n",
    "df_1['temp'].hist(bins=100, figsize=(16, 9))\n",
    "# рисуем распределение температур"
   ],
   "id": "211c5cf961db2cd9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.229318Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = rents_by_week.hist(bins=100, figsize=(16, 9))\n",
    "# объект графика возвращается функцией .hist - его можно положить в переменную\n",
    "# затем добавлять все, что хотим. Добавим title\n",
    "ax[0, 0].set_title('Гистограмма числа поездок понедельно')"
   ],
   "id": "7ae21f1ce09320fa"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что в какие-то недели было очень мало по сравнению с другими.\n",
    "\n",
    "Кажется, что более показательным будет анализ по дням. Давайте сделаем это."
   ],
   "id": "a66752c66b769fd1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.230318Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = df_1.groupby(\n",
    "    df_1['datetime'].dt.dayofyear  # группируем по дням\n",
    ").agg({\n",
    "    'datetime': 'count'  # считаем количество записей в группе\n",
    "}).hist(  # строим гистограмму\n",
    "    bins=100,\n",
    "    figsize=(16, 9)\n",
    ")\n",
    "ax = ax[0, 0]  # matplotlib возвращает двумерный массив, распакуем его\n",
    "ax.set_title('Гистограмма количества поездок ежедневно')\n",
    "ax.set_xlabel('Количество поездок')\n",
    "ax.set_ylabel('Сколько раз было такое количество поездок')"
   ],
   "id": "4f0320b0265cbfd3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересный график. Похоже, в большинстве случаев число поездок не сильно разбрасывалось и лежало в диапазоне 45-50, но бывали и дни, когда число поездок падало в два раза.\n",
    "\n",
    "P.S. если явно не указывать левый и правый конец графика, то они подбираются так, чтобы график вместил все данные. То есть, по графику выше можно сделать вывод, что число поездок в день меньше 50 для всех дней."
   ],
   "id": "dd863b1e822b9867"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Точная настройка через matplotlib\n",
    "На самом деле, все функции выше использовали `matplotlib` для визуализации.\n",
    "\n",
    "Мы даже можем самостоятельно отрисовать те же графики через `matplotlib`, что называется, вручную."
   ],
   "id": "5ee1afd45a5506e3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Через matplotlib.pyplot можно контролировать все аспекты\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "ax.plot(rents_by_week)\n",
    "# добавим еще точки на тот же график - этого не делали в pandas\n",
    "ax.scatter(\n",
    "    # по оси X - индекс. Наша неделя ушла в индекс после группировки\n",
    "    rents_by_week.index,\n",
    "    # по оси Y - значение колонки 0. Она называется temp, можно было по имени обратиться\n",
    "    rents_by_week.iloc[:, 0]\n",
    ")\n",
    "ax.set_xlabel('Номер недели')\n",
    "ax.set_ylabel('Количество поездок')\n",
    "ax.set_title('Количество поездок понедельно')\n",
    "ax.grid(True)\n",
    "fig.show()"
   ],
   "id": "73b531a2029431f2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, рисовать через `matplotlib` напрямую не совсем удобно - надо писать много кода и знать названия методов.\n",
    "Рекомендуем пользоваться `df.hist()` и `df.plot()` для рисования графиков, либо же сторонними библиотеками наподобие `seaborn`.\n",
    "\n",
    "К визуализации данных еще вернемся в блоке \"Машинное обучение\"."
   ],
   "id": "f5c46e57c79d3b7f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение данных"
   ],
   "id": "79baf8233d61b916"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Любой датафрейм из `pandas` можно выгрузить в файл, причем разных форматов.\n",
    "\n",
    "Мы будем учиться выгружать в `CSV` и `Excel`."
   ],
   "id": "c0eb3907f82cfe75"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV\n",
    "Про csv уже говорилось в начале занятия - и в него выгружать очень просто."
   ],
   "id": "6f4f7612ae922ae3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.232318Z"
    }
   },
   "outputs": [],
   "source": [
    "rents_by_week.to_csv('rents_by_week.csv', sep=';')\n",
    "# sep - это разделитель. По умолчанию запятая,\n",
    "# но \";\" лучше читается, если открывать файл в русском Excel"
   ],
   "id": "871d9f7d3a4444b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если не использовать sep=',', то пандас плохо будет читать\n",
    "pd.read_csv('rents_by_week.csv').head(5)"
   ],
   "id": "df6b7a09dba3a655"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.235323Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv('rents_by_week.csv', sep=';').head(5)  # указываем сепаратор явно"
   ],
   "id": "8a674a86497c9721"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel\n",
    "Тут немного сложнее.\n",
    "Для записи в Excel есть несколько библиотек, и они **не поставляются** вместе с pandas - надо ставить отдельно.\n",
    "\n",
    "Мы будем использовать `openpyxl`. Установим ее:"
   ],
   "id": "3522bb670a589814"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.236319Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ],
   "id": "cd1729d2269ad5a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.237318Z"
    }
   },
   "outputs": [],
   "source": [
    "# теперь можем писать в excel\n",
    "# Обратите внимание на engine='openpyxl' - эту бибилотеку только что установили\n",
    "rents_by_week.to_excel('rents_by_week.xlsx', engine='openpyxl')"
   ],
   "id": "6e7c1aa1aee2a6db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-02T09:18:24.238319Z"
    }
   },
   "outputs": [],
   "source": [
    "# можно открыть в MS Excel, а можно и в pandas\n",
    "pd.read_excel('rents_by_week.xlsx', engine='openpyxl').head(5)"
   ],
   "id": "b8171edf728e1be0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аргумент `engine='openpyxl'` является необязательным.\n",
    "\n",
    "Если его пропустить, то pandas будет пытаться определить самостоятельно движок для обработки файла. На практике это может вылиться в то, что он попросит установить доп. бибилиотеки, поэтому мы советуем явно установить один движок и везде указывать его в pandas. В этом случае вы будете четко контролировать зависимости проекта и четко знать, кого винить в случае проблем с файлами Excel. Более подробно про работу `pd.read_excel` можно прочитать в [документации](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html)."
   ],
   "id": "8059a12658963ce6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
